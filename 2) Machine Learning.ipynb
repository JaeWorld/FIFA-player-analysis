{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Potential</th>\n",
       "      <th>Club</th>\n",
       "      <th>Value</th>\n",
       "      <th>Wage</th>\n",
       "      <th>Special</th>\n",
       "      <th>Preferred Foot</th>\n",
       "      <th>...</th>\n",
       "      <th>Marking</th>\n",
       "      <th>StandingTackle</th>\n",
       "      <th>SlidingTackle</th>\n",
       "      <th>GKDiving</th>\n",
       "      <th>GKHandling</th>\n",
       "      <th>GKKicking</th>\n",
       "      <th>GKPositioning</th>\n",
       "      <th>GKReflexes</th>\n",
       "      <th>Release Clause</th>\n",
       "      <th>Position simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L. Messi</td>\n",
       "      <td>31</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>FC Barcelona</td>\n",
       "      <td>133705000</td>\n",
       "      <td>683650</td>\n",
       "      <td>2202</td>\n",
       "      <td>Left</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>274065000</td>\n",
       "      <td>FW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cristiano Ronaldo</td>\n",
       "      <td>33</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>Juventus</td>\n",
       "      <td>93170000</td>\n",
       "      <td>490050</td>\n",
       "      <td>2228</td>\n",
       "      <td>Right</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>153791000</td>\n",
       "      <td>FW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neymar Jr</td>\n",
       "      <td>26</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>Paris Saint-Germain</td>\n",
       "      <td>143385000</td>\n",
       "      <td>350900</td>\n",
       "      <td>2143</td>\n",
       "      <td>Right</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>276001000</td>\n",
       "      <td>FW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>De Gea</td>\n",
       "      <td>27</td>\n",
       "      <td>Spain</td>\n",
       "      <td>91</td>\n",
       "      <td>93</td>\n",
       "      <td>Manchester United</td>\n",
       "      <td>87120000</td>\n",
       "      <td>314600</td>\n",
       "      <td>1471</td>\n",
       "      <td>Right</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>167706000</td>\n",
       "      <td>GK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K. De Bruyne</td>\n",
       "      <td>27</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>123420000</td>\n",
       "      <td>429550</td>\n",
       "      <td>2281</td>\n",
       "      <td>Right</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>237644000</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name  Age Nationality  Overall  Potential  \\\n",
       "0           L. Messi   31   Argentina       94         94   \n",
       "1  Cristiano Ronaldo   33    Portugal       94         94   \n",
       "2          Neymar Jr   26      Brazil       92         93   \n",
       "3             De Gea   27       Spain       91         93   \n",
       "4       K. De Bruyne   27     Belgium       91         92   \n",
       "\n",
       "                  Club      Value    Wage  Special Preferred Foot  ...  \\\n",
       "0         FC Barcelona  133705000  683650     2202           Left  ...   \n",
       "1             Juventus   93170000  490050     2228          Right  ...   \n",
       "2  Paris Saint-Germain  143385000  350900     2143          Right  ...   \n",
       "3    Manchester United   87120000  314600     1471          Right  ...   \n",
       "4      Manchester City  123420000  429550     2281          Right  ...   \n",
       "\n",
       "   Marking  StandingTackle  SlidingTackle GKDiving GKHandling GKKicking  \\\n",
       "0     33.0            28.0           26.0      6.0       11.0      15.0   \n",
       "1     28.0            31.0           23.0      7.0       11.0      15.0   \n",
       "2     27.0            24.0           33.0      9.0        9.0      15.0   \n",
       "3     15.0            21.0           13.0     90.0       85.0      87.0   \n",
       "4     68.0            58.0           51.0     15.0       13.0       5.0   \n",
       "\n",
       "   GKPositioning GKReflexes  Release Clause  Position simplified  \n",
       "0           14.0        8.0       274065000                   FW  \n",
       "1           14.0       11.0       153791000                   FW  \n",
       "2           15.0       11.0       276001000                   FW  \n",
       "3           88.0       94.0       167706000                   GK  \n",
       "4           10.0       13.0       237644000                   MD  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('FIFA2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18159 entries, 0 to 18158\n",
      "Data columns (total 83 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Name                      18159 non-null  object \n",
      " 1   Age                       18159 non-null  int64  \n",
      " 2   Nationality               18159 non-null  object \n",
      " 3   Overall                   18159 non-null  int64  \n",
      " 4   Potential                 18159 non-null  int64  \n",
      " 5   Club                      17918 non-null  object \n",
      " 6   Value                     18159 non-null  int64  \n",
      " 7   Wage                      18159 non-null  int64  \n",
      " 8   Special                   18159 non-null  int64  \n",
      " 9   Preferred Foot            18159 non-null  object \n",
      " 10  International Reputation  18159 non-null  float64\n",
      " 11  Weak Foot                 18159 non-null  float64\n",
      " 12  Skill Moves               18159 non-null  float64\n",
      " 13  Work Rate                 18159 non-null  object \n",
      " 14  Body Type                 18159 non-null  object \n",
      " 15  Position                  18147 non-null  object \n",
      " 16  Jersey Number             18147 non-null  float64\n",
      " 17  Joined                    16654 non-null  object \n",
      " 18  Contract Valid Until      17918 non-null  float64\n",
      " 19  Height                    18159 non-null  float64\n",
      " 20  Weight                    18159 non-null  float64\n",
      " 21  LS                        16122 non-null  float64\n",
      " 22  ST                        16122 non-null  float64\n",
      " 23  RS                        16122 non-null  float64\n",
      " 24  LW                        16122 non-null  float64\n",
      " 25  LF                        16122 non-null  float64\n",
      " 26  CF                        16122 non-null  float64\n",
      " 27  RF                        16122 non-null  float64\n",
      " 28  RW                        16122 non-null  float64\n",
      " 29  LAM                       16122 non-null  float64\n",
      " 30  CAM                       16122 non-null  float64\n",
      " 31  RAM                       16122 non-null  float64\n",
      " 32  LM                        16122 non-null  float64\n",
      " 33  LCM                       16122 non-null  float64\n",
      " 34  CM                        16122 non-null  float64\n",
      " 35  RCM                       16122 non-null  float64\n",
      " 36  RM                        16122 non-null  float64\n",
      " 37  LWB                       16122 non-null  float64\n",
      " 38  LDM                       16122 non-null  float64\n",
      " 39  CDM                       16122 non-null  float64\n",
      " 40  RDM                       16122 non-null  float64\n",
      " 41  RWB                       16122 non-null  float64\n",
      " 42  LB                        16122 non-null  float64\n",
      " 43  LCB                       16122 non-null  float64\n",
      " 44  CB                        16122 non-null  float64\n",
      " 45  RCB                       16122 non-null  float64\n",
      " 46  RB                        16122 non-null  float64\n",
      " 47  Crossing                  18159 non-null  float64\n",
      " 48  Finishing                 18159 non-null  float64\n",
      " 49  HeadingAccuracy           18159 non-null  float64\n",
      " 50  ShortPassing              18159 non-null  float64\n",
      " 51  Volleys                   18159 non-null  float64\n",
      " 52  Dribbling                 18159 non-null  float64\n",
      " 53  Curve                     18159 non-null  float64\n",
      " 54  FKAccuracy                18159 non-null  float64\n",
      " 55  LongPassing               18159 non-null  float64\n",
      " 56  BallControl               18159 non-null  float64\n",
      " 57  Acceleration              18159 non-null  float64\n",
      " 58  SprintSpeed               18159 non-null  float64\n",
      " 59  Agility                   18159 non-null  float64\n",
      " 60  Reactions                 18159 non-null  float64\n",
      " 61  Balance                   18159 non-null  float64\n",
      " 62  ShotPower                 18159 non-null  float64\n",
      " 63  Jumping                   18159 non-null  float64\n",
      " 64  Stamina                   18159 non-null  float64\n",
      " 65  Strength                  18159 non-null  float64\n",
      " 66  LongShots                 18159 non-null  float64\n",
      " 67  Aggression                18159 non-null  float64\n",
      " 68  Interceptions             18159 non-null  float64\n",
      " 69  Positioning               18159 non-null  float64\n",
      " 70  Vision                    18159 non-null  float64\n",
      " 71  Penalties                 18159 non-null  float64\n",
      " 72  Composure                 18159 non-null  float64\n",
      " 73  Marking                   18159 non-null  float64\n",
      " 74  StandingTackle            18159 non-null  float64\n",
      " 75  SlidingTackle             18159 non-null  float64\n",
      " 76  GKDiving                  18159 non-null  float64\n",
      " 77  GKHandling                18159 non-null  float64\n",
      " 78  GKKicking                 18159 non-null  float64\n",
      " 79  GKPositioning             18159 non-null  float64\n",
      " 80  GKReflexes                18159 non-null  float64\n",
      " 81  Release Clause            18159 non-null  int64  \n",
      " 82  Position simplified       18159 non-null  object \n",
      "dtypes: float64(67), int64(7), object(9)\n",
      "memory usage: 11.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18159, 83)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세부 능력치를 Features로, 포지션을 Target으로 여러가지 모델을 돌려보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return pred, pred_proba\n",
    "\n",
    "def get_clf_eval(clf, X_train, X_test, y_train, y_test):\n",
    "    pred, pred_proba = get_pred(clf, X_train, X_test, y_train, y_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred, average='macro')\n",
    "    recall = recall_score(y_test, pred, average='macro')\n",
    "    f1 = f1_score(y_test, pred, average='macro')\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    \n",
    "    print(f'{clf}\\n정확도: {accuracy:.4f}, 정밀도: {precision:.4f}, 재현율: {recall:.4f}, F1: {f1:.4f} \\n 오차행렬: {confusion}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14527, 34), (3632, 34))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, 47:81]\n",
    "y = pd.factorize(data['Position simplified'])[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "정확도: 0.8722, 정밀도: 0.8916, 재현율: 0.8864, F1: 0.8889 \n",
      " 오차행렬: [[ 557    0  137    6]\n",
      " [   2  371    0    0]\n",
      " [ 115    0 1165   94]\n",
      " [   0    0  110 1075]]\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "정확도: 0.8095, 정밀도: 0.8354, 재현율: 0.8360, F1: 0.8356 \n",
      " 오차행렬: [[ 516    1  174    9]\n",
      " [   1  371    1    0]\n",
      " [ 195    0 1036  143]\n",
      " [   4    0  164 1017]]\n",
      "\n",
      "KNeighborsClassifier()\n",
      "정확도: 0.8527, 정밀도: 0.8742, 재현율: 0.8690, F1: 0.8715 \n",
      " 오차행렬: [[ 534    0  162    4]\n",
      " [   1  371    1    0]\n",
      " [ 139    0 1130  105]\n",
      " [   1    0  122 1062]]\n",
      "\n",
      "AdaBoostClassifier()\n",
      "정확도: 0.7382, 정밀도: 0.7741, 재현율: 0.8032, F1: 0.7767 \n",
      " 오차행렬: [[ 595    2   98    5]\n",
      " [   2  371    0    0]\n",
      " [ 396    0  682  296]\n",
      " [   2    2  148 1033]]\n",
      "\n",
      "RandomForestClassifier()\n",
      "정확도: 0.8747, 정밀도: 0.8925, 재현율: 0.8864, F1: 0.8892 \n",
      " 오차행렬: [[ 543    0  154    3]\n",
      " [   2  371    0    0]\n",
      " [ 113    0 1160  101]\n",
      " [   0    0   82 1103]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "ada_clf = AdaBoostClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "get_clf_eval(lr_clf, X_train, X_test, y_train, y_test)\n",
    "get_clf_eval(dt_clf, X_train, X_test, y_train, y_test)\n",
    "get_clf_eval(knn_clf, X_train, X_test, y_train, y_test)\n",
    "get_clf_eval(ada_clf, X_train, X_test, y_train, y_test)\n",
    "get_clf_eval(rf_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부스트 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=6, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "정확도: 0.8722, 정밀도: 0.8904, 재현율: 0.8828, F1: 0.8862 \n",
      " 오차행렬: [[ 533    1  161    5]\n",
      " [   1  371    1    0]\n",
      " [ 114    0 1167   93]\n",
      " [   0    0   88 1097]]\n",
      "\n",
      "LGBMClassifier()\n",
      "정확도: 0.8789, 정밀도: 0.8953, 재현율: 0.8891, F1: 0.8919 \n",
      " 오차행렬: [[ 543    1  152    4]\n",
      " [   2  371    0    0]\n",
      " [ 109    1 1176   88]\n",
      " [   0    0   83 1102]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier()\n",
    "lgbm_clf = LGBMClassifier()\n",
    "\n",
    "get_clf_eval(xgb_clf, X_train, X_test, y_train, y_test)\n",
    "get_clf_eval(lgbm_clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression, RandomForest, xgboost, lightgbm가 높은 성능을 보임 -> 파라미터 튜닝!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2, 'penalty': 'l2'}\n",
      "0.8793971259293146\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "\n",
    "params = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "grid_lr = GridSearchCV(lr_clf, param_grid=params, cv=3, refit=True)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(grid_lr.best_params_)\n",
    "print(grid_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 정확도:  0.8725\n"
     ]
    }
   ],
   "source": [
    "lr_clf1 = LogisticRegression(C=5, penalty='l2')\n",
    "lr_clf1.fit(X_train, y_train)\n",
    "pred_lr = lr_clf1.predict(X_test)\n",
    "\n",
    "print('로지스틱 회귀 정확도: ', round(accuracy_score(y_test, pred_lr), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 30}\n",
      "0.8790528160446188\n"
     ]
    }
   ],
   "source": [
    "# RF\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [30],\n",
    "    'max_depth': [8, 12, 15, 20],\n",
    "    'min_samples_leaf': [4, 6, 8, 12, 18],\n",
    "    'min_samples_split': [4, 6, 8, 16, 20]\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "grid_rf = GridSearchCV(rf_clf, param_grid=params, cv=3, refit=True)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_rf.best_params_)\n",
    "print(grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 정확도:  0.8756\n"
     ]
    }
   ],
   "source": [
    "rf_clf1 = RandomForestClassifier(max_depth= 15, min_samples_leaf= 8, \n",
    "                                 min_samples_split= 8, n_estimators= 100)\n",
    "rf_clf1.fit(X_train, y_train)\n",
    "pred_rf = rf_clf1.predict(X_test)\n",
    "\n",
    "print('랜덤포레스트 정확도: ', round(accuracy_score(y_test, pred_rf), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x291709e84f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_imp_rf = rf_clf1.feature_importances_\n",
    "f_imp_rf = pd.Series(f_imp_rf, index=X_train.columns)\n",
    "f_imp_rf = f_imp_rf.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Random Forest feature importances')\n",
    "sns.barplot(x=f_imp_rf, y=f_imp_rf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:28:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:30:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:30:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:31:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:32:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:32:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 30}\n",
      "0.8843532436899478\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [30],\n",
    "    'max_depth': [4, 6, 8, 10, 15],\n",
    "    'min_samples_leaf': [4, 6, 8, 12, 16],\n",
    "    'min_samples_split': [4, 6, 8, 12, 16]\n",
    "}\n",
    "\n",
    "xgb_clf = XGBClassifier(silent=True)\n",
    "grid_xgb = GridSearchCV(xgb_clf, param_grid=params, cv=3, refit=True)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(grid_xgb.best_params_)\n",
    "print(grid_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:32:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:32:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB 정확도:  0.8756\n"
     ]
    }
   ],
   "source": [
    "xgb_clf1 = XGBClassifier(max_depth=8, min_samples_leaf=8, min_samples_split=4, n_estimators=100)\n",
    "xgb_clf1.fit(X_train, y_train)\n",
    "\n",
    "pred_xgb = xgb_clf1.predict(X_test)\n",
    "print('XGB 정확도: ', round(accuracy_score(y_test, pred_xgb), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29173aab1c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "plot_importance(xgb_clf1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightGBM\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [10],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'num_leaves': [30, 50, 70, 100],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_iterations': [100, 120, 150, 200]\n",
    "}\n",
    "\n",
    "lgbm_clf = LGBMClassifier()\n",
    "grid_lgbm = GridSearchCV(lgbm_clf, param_grid=params, cv=3, refit=True)\n",
    "grid_lgbm.fit(X_train, y_train)\n",
    "\n",
    "print(grid_lgbm.best_params_)\n",
    "print(grid_lgbm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM 정확도:  0.8747\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf1 = LGBMClassifier(max_depth=4, min_child_weight=1,\n",
    "                           learning_rate=0.1, subsample=0.6,\n",
    "                          num_leaves=30, num_iterations=100, n_estimators=100)\n",
    "\n",
    "lgbm_clf1.fit(X_train, y_train)\n",
    "pred_lgbm = lgbm_clf1.predict(X_test)\n",
    "\n",
    "print('LGBM 정확도: ', round(accuracy_score(y_test, pred_lgbm), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29173a6ffa0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_importances = lgbm_clf1.feature_importances_\n",
    "f_importances = pd.Series(f_importances, index=X_train.columns)\n",
    "f_top = f_importances.sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.barplot(x=f_top, y=f_top.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, pred_lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Description</th>        <th class=\"col_heading level0 col1\" >Value</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row1_col1\" class=\"data row1 col1\" >Position simplified</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row2_col0\" class=\"data row2 col0\" >Target Type</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row3_col0\" class=\"data row3 col0\" >Label Encoded</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row3_col1\" class=\"data row3 col1\" >DF: 0, FW: 1, GK: 2, MD: 3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row4_col0\" class=\"data row4 col0\" >Original Data</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row4_col1\" class=\"data row4 col1\" >(18159, 35)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row5_col0\" class=\"data row5 col0\" >Missing Values</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row5_col1\" class=\"data row5 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row6_col0\" class=\"data row6 col0\" >Numeric Features</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row6_col1\" class=\"data row6 col1\" >34</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row7_col0\" class=\"data row7 col0\" >Categorical Features</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row8_col0\" class=\"data row8 col0\" >Ordinal Features</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row8_col1\" class=\"data row8 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row9_col0\" class=\"data row9 col0\" >High Cardinality Features</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row10_col0\" class=\"data row10 col0\" >High Cardinality Method</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row10_col1\" class=\"data row10 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row11_col0\" class=\"data row11 col0\" >Transformed Train Set</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row11_col1\" class=\"data row11 col1\" >(14527, 34)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row12_col0\" class=\"data row12 col0\" >Transformed Test Set</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row12_col1\" class=\"data row12 col1\" >(3632, 34)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row13_col0\" class=\"data row13 col0\" >Shuffle Train-Test</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row14_col0\" class=\"data row14 col0\" >Stratify Train-Test</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row16_col1\" class=\"data row16 col1\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row20_col1\" class=\"data row20 col1\" >clf-default-name</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row21_col1\" class=\"data row21 col1\" >5367</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row22_col0\" class=\"data row22 col0\" >Imputation Type</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row22_col1\" class=\"data row22 col1\" >simple</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row23_col0\" class=\"data row23 col0\" >Iterative Imputation Iteration</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row23_col1\" class=\"data row23 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row24_col0\" class=\"data row24 col0\" >Numeric Imputer</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row24_col1\" class=\"data row24 col1\" >mean</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row25_col0\" class=\"data row25 col0\" >Iterative Imputation Numeric Model</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row25_col1\" class=\"data row25 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row26_col0\" class=\"data row26 col0\" >Categorical Imputer</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row26_col1\" class=\"data row26 col1\" >constant</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row27_col0\" class=\"data row27 col0\" >Iterative Imputation Categorical Model</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row27_col1\" class=\"data row27 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row28_col0\" class=\"data row28 col0\" >Unknown Categoricals Handling</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row28_col1\" class=\"data row28 col1\" >least_frequent</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row29_col0\" class=\"data row29 col0\" >Normalize</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row29_col1\" class=\"data row29 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row30_col0\" class=\"data row30 col0\" >Normalize Method</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row30_col1\" class=\"data row30 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row31_col0\" class=\"data row31 col0\" >Transformation</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row32_col0\" class=\"data row32 col0\" >Transformation Method</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row32_col1\" class=\"data row32 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row33_col0\" class=\"data row33 col0\" >PCA</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row34_col0\" class=\"data row34 col0\" >PCA Method</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row34_col1\" class=\"data row34 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row35_col0\" class=\"data row35 col0\" >PCA Components</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row35_col1\" class=\"data row35 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row36_col0\" class=\"data row36 col0\" >Ignore Low Variance</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row36_col1\" class=\"data row36 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row37_col0\" class=\"data row37 col0\" >Combine Rare Levels</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row37_col1\" class=\"data row37 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row38_col0\" class=\"data row38 col0\" >Rare Level Threshold</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row38_col1\" class=\"data row38 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row39_col0\" class=\"data row39 col0\" >Numeric Binning</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row39_col1\" class=\"data row39 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row40_col0\" class=\"data row40 col0\" >Remove Outliers</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row40_col1\" class=\"data row40 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row41_col0\" class=\"data row41 col0\" >Outliers Threshold</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row41_col1\" class=\"data row41 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row42_col0\" class=\"data row42 col0\" >Remove Multicollinearity</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row42_col1\" class=\"data row42 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row43_col0\" class=\"data row43 col0\" >Multicollinearity Threshold</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row43_col1\" class=\"data row43 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row44_col0\" class=\"data row44 col0\" >Clustering</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row44_col1\" class=\"data row44 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row45_col0\" class=\"data row45 col0\" >Clustering Iteration</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row45_col1\" class=\"data row45 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row46_col0\" class=\"data row46 col0\" >Polynomial Features</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row46_col1\" class=\"data row46 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row47_col0\" class=\"data row47 col0\" >Polynomial Degree</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row47_col1\" class=\"data row47 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row48_col0\" class=\"data row48 col0\" >Trignometry Features</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row48_col1\" class=\"data row48 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row49_col0\" class=\"data row49 col0\" >Polynomial Threshold</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row49_col1\" class=\"data row49 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row50_col0\" class=\"data row50 col0\" >Group Features</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row50_col1\" class=\"data row50 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row51_col0\" class=\"data row51 col0\" >Feature Selection</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row51_col1\" class=\"data row51 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row52_col0\" class=\"data row52 col0\" >Features Selection Threshold</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row52_col1\" class=\"data row52 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row53_col0\" class=\"data row53 col0\" >Feature Interaction</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row53_col1\" class=\"data row53 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row54_col0\" class=\"data row54 col0\" >Feature Ratio</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row54_col1\" class=\"data row54 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row55_col0\" class=\"data row55 col0\" >Interaction Threshold</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row55_col1\" class=\"data row55 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row56_col0\" class=\"data row56 col0\" >Fix Imbalance</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row56_col1\" class=\"data row56 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row57_col0\" class=\"data row57 col0\" >Fix Imbalance Method</td>\n",
       "                        <td id=\"T_c0b2e422_604a_11eb_b0a0_34cff6c63a17row57_col1\" class=\"data row57 col1\" >SMOTE</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29179eec610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "\n",
    "data = pd.read_csv('./FIFA2.csv')\n",
    "\n",
    "XX = data.loc[:, 'Crossing':'GKReflexes']\n",
    "yy = data.loc[:, 'Position simplified']\n",
    "\n",
    "data_auto = pd.concat([XX, yy], axis=1)\n",
    "clf = setup(data=data_auto, target='Position simplified', train_size=0.8, session_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_01557932_604b_11eb_8735_34cff6c63a17 th {\n",
       "          text-align: left;\n",
       "    }    #T_01557932_604b_11eb_8735_34cff6c63a17row0_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row0_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row0_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row0_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row0_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row0_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row0_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row0_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row0_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row1_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row1_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row1_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row1_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row1_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row1_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row1_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row1_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row1_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row2_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row2_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row2_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row2_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row2_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row2_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row2_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row2_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row2_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row3_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row3_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row3_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row3_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row3_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row3_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row3_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row3_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row3_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row4_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row4_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row4_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row4_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row4_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row4_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row4_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row4_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row4_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row5_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row5_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row5_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row5_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row5_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row5_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row5_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row5_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row5_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row6_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row6_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row6_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row6_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row6_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row6_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row6_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row6_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row6_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row7_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row7_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row7_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row7_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row7_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row7_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row7_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row7_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row7_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row8_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row8_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row8_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row8_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row8_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row8_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row8_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row8_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row8_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row9_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row9_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row9_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row9_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row9_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row9_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row9_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row9_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row9_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row10_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row10_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row10_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row10_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row10_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row10_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row10_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row10_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row10_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row11_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row11_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row11_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row11_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row11_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row11_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row11_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row11_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row11_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row12_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row12_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row12_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row12_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row12_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row12_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row12_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row12_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row12_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row13_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row13_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row13_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row13_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row13_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row13_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row13_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row13_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row13_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            background-color:  yellow;\n",
       "            background-color:  lightgrey;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row14_col0 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row14_col1 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row14_col2 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row14_col3 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row14_col4 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row14_col5 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row14_col6 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row14_col7 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "        }    #T_01557932_604b_11eb_8735_34cff6c63a17row14_col8 {\n",
       "            text-align:  left;\n",
       "            text-align:  left;\n",
       "            : ;\n",
       "            background-color:  lightgrey;\n",
       "        }</style><table id=\"T_01557932_604b_11eb_8735_34cff6c63a17\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >AUC</th>        <th class=\"col_heading level0 col3\" >Recall</th>        <th class=\"col_heading level0 col4\" >Prec.</th>        <th class=\"col_heading level0 col5\" >F1</th>        <th class=\"col_heading level0 col6\" >Kappa</th>        <th class=\"col_heading level0 col7\" >MCC</th>        <th class=\"col_heading level0 col8\" >TT (Sec)</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row0\" class=\"row_heading level0 row0\" >catboost</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row0_col1\" class=\"data row0 col1\" >0.8849</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row0_col2\" class=\"data row0 col2\" >0.9730</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row0_col3\" class=\"data row0 col3\" >0.8913</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row0_col4\" class=\"data row0 col4\" >0.8849</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row0_col5\" class=\"data row0 col5\" >0.8844</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row0_col6\" class=\"data row0 col6\" >0.8364</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row0_col7\" class=\"data row0 col7\" >0.8367</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row0_col8\" class=\"data row0 col8\" >9.5400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row1\" class=\"row_heading level0 row1\" >gbc</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row1_col0\" class=\"data row1 col0\" >Gradient Boosting Classifier</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row1_col1\" class=\"data row1 col1\" >0.8836</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row1_col2\" class=\"data row1 col2\" >0.9720</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row1_col3\" class=\"data row1 col3\" >0.8920</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row1_col4\" class=\"data row1 col4\" >0.8834</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row1_col5\" class=\"data row1 col5\" >0.8832</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row1_col6\" class=\"data row1 col6\" >0.8347</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row1_col7\" class=\"data row1 col7\" >0.8349</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row1_col8\" class=\"data row1 col8\" >4.7333</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row2\" class=\"row_heading level0 row2\" >xgboost</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row2_col0\" class=\"data row2 col0\" >Extreme Gradient Boosting</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row2_col1\" class=\"data row2 col1\" >0.8835</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row2_col2\" class=\"data row2 col2\" >0.9716</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row2_col3\" class=\"data row2 col3\" >0.8909</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row2_col4\" class=\"data row2 col4\" >0.8833</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row2_col5\" class=\"data row2 col5\" >0.8831</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row2_col6\" class=\"data row2 col6\" >0.8346</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row2_col7\" class=\"data row2 col7\" >0.8348</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row2_col8\" class=\"data row2 col8\" >2.3400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row3\" class=\"row_heading level0 row3\" >lightgbm</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row3_col0\" class=\"data row3 col0\" >Light Gradient Boosting Machine</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row3_col1\" class=\"data row3 col1\" >0.8833</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row3_col2\" class=\"data row3 col2\" >0.9723</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row3_col3\" class=\"data row3 col3\" >0.8905</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row3_col4\" class=\"data row3 col4\" >0.8831</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row3_col5\" class=\"data row3 col5\" >0.8828</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row3_col6\" class=\"data row3 col6\" >0.8343</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row3_col7\" class=\"data row3 col7\" >0.8345</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row3_col8\" class=\"data row3 col8\" >0.5467</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row4\" class=\"row_heading level0 row4\" >rf</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row4_col0\" class=\"data row4 col0\" >Random Forest Classifier</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row4_col1\" class=\"data row4 col1\" >0.8792</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row4_col2\" class=\"data row4 col2\" >0.9704</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row4_col3\" class=\"data row4 col3\" >0.8877</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row4_col4\" class=\"data row4 col4\" >0.8791</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row4_col5\" class=\"data row4 col5\" >0.8786</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row4_col6\" class=\"data row4 col6\" >0.8283</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row4_col7\" class=\"data row4 col7\" >0.8286</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row4_col8\" class=\"data row4 col8\" >0.4967</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row5\" class=\"row_heading level0 row5\" >et</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row5_col0\" class=\"data row5 col0\" >Extra Trees Classifier</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row5_col1\" class=\"data row5 col1\" >0.8789</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row5_col2\" class=\"data row5 col2\" >0.9704</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row5_col3\" class=\"data row5 col3\" >0.8857</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row5_col4\" class=\"data row5 col4\" >0.8792</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row5_col5\" class=\"data row5 col5\" >0.8783</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row5_col6\" class=\"data row5 col6\" >0.8277</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row5_col7\" class=\"data row5 col7\" >0.8282</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row5_col8\" class=\"data row5 col8\" >0.3500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row6\" class=\"row_heading level0 row6\" >lr</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row6_col0\" class=\"data row6 col0\" >Logistic Regression</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row6_col1\" class=\"data row6 col1\" >0.8785</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row6_col2\" class=\"data row6 col2\" >0.9706</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row6_col3\" class=\"data row6 col3\" >0.8889</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row6_col4\" class=\"data row6 col4\" >0.8786</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row6_col5\" class=\"data row6 col5\" >0.8783</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row6_col6\" class=\"data row6 col6\" >0.8276</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row6_col7\" class=\"data row6 col7\" >0.8277</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row6_col8\" class=\"data row6 col8\" >2.4100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row7\" class=\"row_heading level0 row7\" >lda</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row7_col0\" class=\"data row7 col0\" >Linear Discriminant Analysis</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row7_col1\" class=\"data row7 col1\" >0.8681</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row7_col2\" class=\"data row7 col2\" >0.9655</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row7_col3\" class=\"data row7 col3\" >0.8830</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row7_col4\" class=\"data row7 col4\" >0.8686</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row7_col5\" class=\"data row7 col5\" >0.8682</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row7_col6\" class=\"data row7 col6\" >0.8132</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row7_col7\" class=\"data row7 col7\" >0.8133</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row7_col8\" class=\"data row7 col8\" >0.0800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row8\" class=\"row_heading level0 row8\" >ridge</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row8_col0\" class=\"data row8 col0\" >Ridge Classifier</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row8_col1\" class=\"data row8 col1\" >0.8665</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row8_col2\" class=\"data row8 col2\" >0.0000</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row8_col3\" class=\"data row8 col3\" >0.8792</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row8_col4\" class=\"data row8 col4\" >0.8670</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row8_col5\" class=\"data row8 col5\" >0.8665</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row8_col6\" class=\"data row8 col6\" >0.8105</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row8_col7\" class=\"data row8 col7\" >0.8107</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row8_col8\" class=\"data row8 col8\" >0.0733</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row9\" class=\"row_heading level0 row9\" >knn</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row9_col0\" class=\"data row9 col0\" >K Neighbors Classifier</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row9_col1\" class=\"data row9 col1\" >0.8623</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row9_col2\" class=\"data row9 col2\" >0.9517</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row9_col3\" class=\"data row9 col3\" >0.8739</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row9_col4\" class=\"data row9 col4\" >0.8630</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row9_col5\" class=\"data row9 col5\" >0.8623</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row9_col6\" class=\"data row9 col6\" >0.8044</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row9_col7\" class=\"data row9 col7\" >0.8047</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row9_col8\" class=\"data row9 col8\" >1.7367</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row10\" class=\"row_heading level0 row10\" >qda</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row10_col0\" class=\"data row10 col0\" >Quadratic Discriminant Analysis</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row10_col1\" class=\"data row10 col1\" >0.8555</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row10_col2\" class=\"data row10 col2\" >0.9641</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row10_col3\" class=\"data row10 col3\" >0.8777</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row10_col4\" class=\"data row10 col4\" >0.8559</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row10_col5\" class=\"data row10 col5\" >0.8549</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row10_col6\" class=\"data row10 col6\" >0.7964</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row10_col7\" class=\"data row10 col7\" >0.7971</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row10_col8\" class=\"data row10 col8\" >0.0733</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row11\" class=\"row_heading level0 row11\" >svm</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row11_col0\" class=\"data row11 col0\" >SVM - Linear Kernel</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row11_col1\" class=\"data row11 col1\" >0.8528</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row11_col2\" class=\"data row11 col2\" >0.0000</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row11_col3\" class=\"data row11 col3\" >0.8632</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row11_col4\" class=\"data row11 col4\" >0.8666</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row11_col5\" class=\"data row11 col5\" >0.8536</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row11_col6\" class=\"data row11 col6\" >0.7899</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row11_col7\" class=\"data row11 col7\" >0.7954</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row11_col8\" class=\"data row11 col8\" >0.1700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row12\" class=\"row_heading level0 row12\" >dt</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row12_col0\" class=\"data row12 col0\" >Decision Tree Classifier</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row12_col1\" class=\"data row12 col1\" >0.8111</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row12_col2\" class=\"data row12 col2\" >0.8613</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row12_col3\" class=\"data row12 col3\" >0.8353</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row12_col4\" class=\"data row12 col4\" >0.8113</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row12_col5\" class=\"data row12 col5\" >0.8112</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row12_col6\" class=\"data row12 col6\" >0.7328</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row12_col7\" class=\"data row12 col7\" >0.7328</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row12_col8\" class=\"data row12 col8\" >0.1033</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row13\" class=\"row_heading level0 row13\" >nb</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row13_col0\" class=\"data row13 col0\" >Naive Bayes</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row13_col1\" class=\"data row13 col1\" >0.7859</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row13_col2\" class=\"data row13 col2\" >0.9309</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row13_col3\" class=\"data row13 col3\" >0.8323</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row13_col4\" class=\"data row13 col4\" >0.7876</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row13_col5\" class=\"data row13 col5\" >0.7850</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row13_col6\" class=\"data row13 col6\" >0.6998</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row13_col7\" class=\"data row13 col7\" >0.7010</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row13_col8\" class=\"data row13 col8\" >0.0700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_01557932_604b_11eb_8735_34cff6c63a17level0_row14\" class=\"row_heading level0 row14\" >ada</th>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row14_col0\" class=\"data row14 col0\" >Ada Boost Classifier</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row14_col1\" class=\"data row14 col1\" >0.6733</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row14_col2\" class=\"data row14 col2\" >0.8002</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row14_col3\" class=\"data row14 col3\" >0.7547</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row14_col4\" class=\"data row14 col4\" >0.6964</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row14_col5\" class=\"data row14 col5\" >0.6512</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row14_col6\" class=\"data row14 col6\" >0.5515</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row14_col7\" class=\"data row14 col7\" >0.5724</td>\n",
       "                        <td id=\"T_01557932_604b_11eb_8735_34cff6c63a17row14_col8\" class=\"data row14 col8\" >0.3367</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2916d799790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best4models = compare_models(sort='Accuracy', n_select=4, fold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic, lightgbm, RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x291740885b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_corr = X.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(X_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 정확도:  0.8725\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(penalty='l2', C=5, multi_class='multinomial')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "pred_lr = lr_clf.predict(X_test)\n",
    "print('로지스틱 회귀 정확도: ', round(accuracy_score(y_test, pred_lr), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 정확도:  0.875\n"
     ]
    }
   ],
   "source": [
    "rf_clf1 = RandomForestClassifier(max_depth= 20, min_samples_leaf= 6, \n",
    "                                 min_samples_split= 8, n_estimators= 500)\n",
    "rf_clf1.fit(X_train, y_train)\n",
    "pred_rf = rf_clf1.predict(X_test)\n",
    "\n",
    "print('랜덤포레스트 정확도: ', round(accuracy_score(y_test, pred_rf), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM 정확도:  0.8789\n"
     ]
    }
   ],
   "source": [
    "# lgbm_clf = LGBMClassifier(max_depth=20, min_samples_leaf=8,\n",
    "#                           min_samples_split=3, n_estimators=100)\n",
    "lgbm_clf1 = LGBMClassifier(max_depth=4, min_child_weight=1,\n",
    "                           learning_rate=0.1, subsample=0.6,\n",
    "                          num_leaves=30, num_iterations=100, n_estimators=500)\n",
    "\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "pred_lgbm = lgbm_clf.predict(X_test)\n",
    "\n",
    "print('LGBM 정확도: ', round(accuracy_score(y_test, pred_lgbm), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 47:81]\n",
    "y = pd.factorize(data['Position simplified'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 튜닝\n",
    "\n",
    "X = data.iloc[:, 47:81]\n",
    "y = pd.factorize(data['Position simplified'])[0]\n",
    "\n",
    "X['gkdiving_positioning_ratio'] = X['GKDiving'] / X['Positioning']\n",
    "# X['gkpositioning_positioning_ratio'] = X['GKPositioning'] / X['Positioning']\n",
    "# X['gkreflexes_positioning_ratio'] = X['GKReflexes'] / X['Positioning']\n",
    "# X['gkhandling_positioning_ratio'] = X['GKHandling'] / X['Positioning']\n",
    "# X['gkkicking_positioning_ratio'] = X['GKKicking'] / X['Positioning']\n",
    "\n",
    "\n",
    "# X['finishing_sprint_ratio'] = X['Finishing'] / X['SprintSpeed'] \n",
    "# X['finishing_acceleration_ratio'] = X['Finishing'] / X['Acceleration']\n",
    "\n",
    "# X['interceptions_vision_diff'] = X['Interceptions'] - X['Vision']\n",
    "\n",
    "# X['curve_finishing_ratio'] = X['Curve'] / X['Finishing']\n",
    "# X['curve_finishing_diff'] = X['Curve'] - X['Finishing']\n",
    "#X['fkaccuracy_marking_ratio'] = X['FKAccuracy'] / X['Marking']\n",
    "#X['fkaccuracy_marking_diff'] = X['FKAccuracy'] - X['Marking']\n",
    "#X['fkaccuracy_tackle_ratio'] = X['FKAccuracy'] / X['SlidingTackle']\n",
    "\n",
    "X['fkaccuracy_tackle_diff'] = X['FKAccuracy'] - X['SlidingTackle']\n",
    "X['finishing_tackle_ratio'] = X['Finishing'] / X['SlidingTackle']\n",
    "X['finishing_tackle_diff'] = X['Finishing'] - X['SlidingTackle']\n",
    "\n",
    "\n",
    "X.drop(['Strength','GKDiving', 'GKPositioning', 'GKReflexes', 'GKKicking', 'GKHandling'], axis=1, inplace=True)\n",
    "# X.drop(['Strength','Curve','BallControl','Reactions', 'Composure','Aggression','Agility',\n",
    "#         'Balance','Jumping','Acceleration','SprintSpeed','ShotPower','Stamina','FKAccuracy','Penalties',\n",
    "#         'GKPositioning', 'GKReflexes', 'GKKicking', 'GKHandling'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 정확도(피처 튜닝 후):  0.8744\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(penalty='l2', C=0.08, intercept_scaling=-70, max_iter=100, multi_class='multinomial')\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred_lr = lr_clf.predict(X_test)\n",
    "\n",
    "print('로지스틱 회귀 정확도(피처 튜닝 후): ', round(accuracy_score(y_test, pred_lr), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(max_depth=20, min_samples_leaf= 6, \n",
    "                                 min_samples_split=8, n_estimators= 500)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "print('랜덤포레스트 정확도(피처 튜닝 후): ', round(accuracy_score(y_test, pred_rf), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_imp_rf = rf_clf.feature_importances_\n",
    "f_imp_rf = pd.Series(f_imp_rf, index=X_train.columns)\n",
    "f_imp_rf = f_imp_rf.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Random Forest feature importances')\n",
    "sns.barplot(x=f_imp_rf, y=f_imp_rf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_clf = LGBMClassifier(max_depth=20, min_samples_leaf=8,\n",
    "#                           min_samples_split=3, n_estimators=100)\n",
    "lgbm_clf1 = LGBMClassifier(max_depth=4, min_child_weight=1,\n",
    "                           learning_rate=0.1, subsample=0.6,\n",
    "                          num_leaves=30, num_iterations=100, n_estimators=100)\n",
    "\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "pred_lgbm = lgbm_clf.predict(X_test)\n",
    "\n",
    "print('LGBM 정확도(피처 튜닝 후): ', round(accuracy_score(y_test, pred_lgbm), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_importances = lgbm_clf.feature_importances_\n",
    "f_importances = pd.Series(f_importances, index=X_train.columns)\n",
    "f_top = f_importances.sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.barplot(x=f_top, y=f_top.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:, 47:81]\n",
    "y = pd.factorize(data['Position simplified'])[0]\n",
    "\n",
    "cols = X.columns\n",
    "\n",
    "for col in cols:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    sns.distplot(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "xgb = LGBMClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "\n",
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, n_jobs=4, cv=skf.split(X_train,y_train), verbose=3, random_state=1001 )\n",
    "\n",
    "random_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "results = pd.DataFrame(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf = LGBMClassifier(boosting_type='gbdt',\n",
    "                                            class_weight=None,\n",
    "                                            colsample_bytree=1.0,\n",
    "                                            importance_type='split',\n",
    "                                            learning_rate=0.02, max_depth=-1,\n",
    "                                            min_child_samples=20,\n",
    "                                            min_child_weight=0.001,\n",
    "                                            min_split_gain=0.0,\n",
    "                                            n_estimators=600, n_jobs=-1,\n",
    "                                            nthread=1, num_leaves=31,\n",
    "                                            objective='multi:softprob', random_state=0,\n",
    "                                            reg_lambda=0.0, silent=True,\n",
    "                                            subsample=1.0,\n",
    "                                            subsample_for_bin=200000,\n",
    "                                            subsample_freq=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: subsample1\n",
      "0.8763766519823789\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf.fit(X_train, y_train)\n",
    "\n",
    "pred = lgbm_clf.predict(X_test)\n",
    "\n",
    "print(lgbm_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "base_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LGBMClassifier()\n",
    ")\n",
    "\n",
    "bagging_model = BaggingClassifier(base_model, n_estimators=10, max_samples=0.5, max_features=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8700417959765214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cross_val = cross_validate(\n",
    "    estimator = base_model,\n",
    "    X = X_test,\n",
    "    y = y_test,\n",
    "    cv= 5\n",
    ")\n",
    "\n",
    "print(cross_val['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8774771599956044\n"
     ]
    }
   ],
   "source": [
    "base_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel='rbf')\n",
    ")\n",
    "\n",
    "bagging_model = BaggingClassifier(base_model, n_estimators=10, max_samples=0.5, max_features=0.5)\n",
    "\n",
    "cross_val = cross_validate(\n",
    "    estimator = base_model,\n",
    "    X = X_test,\n",
    "    y = y_test,\n",
    "    cv= 5\n",
    ")\n",
    "\n",
    "print(cross_val['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 별 배깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 47:81]\n",
    "y = pd.factorize(data['Position simplified'])[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 정확도\n",
      "0.8725\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=0.08, intercept_scaling=-70, max_iter=69,\n",
    "                                    multi_class='multinomial',\n",
    "                                    random_state=0)\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "\n",
    "print('로지스틱 회귀 정확도')\n",
    "print(round(accuracy_score(y_test, lr_pred), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 배깅 정확도\n",
      "0.8648\n"
     ]
    }
   ],
   "source": [
    "# LR 배깅\n",
    "\n",
    "lr_clf = LogisticRegression(C=0.08, intercept_scaling=-70, max_iter=69,\n",
    "                                    multi_class='multinomial',\n",
    "                                    random_state=0)\n",
    "\n",
    "bagging_clf = BaggingClassifier(lr_clf, n_estimators=10, max_samples=0.5, max_features=0.5)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "bagging_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "print('로지스틱 회귀 배깅 정확도')\n",
    "print(round(accuracy_score(y_test, bagging_pred), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 정확도\n",
      "0.8753\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(max_depth=16, min_samples_leaf=3, min_samples_split=5,\n",
    "                               n_estimators=500)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "\n",
    "print('랜덤포레스트 정확도')\n",
    "print(round(accuracy_score(y_test, rf_pred), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 배깅 정확도\n",
      "0.8772\n"
     ]
    }
   ],
   "source": [
    "# RF 배깅\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=16, min_samples_leaf=3, min_samples_split=5,\n",
    "                               n_estimators=500)\n",
    "\n",
    "bagging_clf = BaggingClassifier(rf_clf, n_estimators=10, max_samples=0.5, max_features=0.5)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "bagging_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "print('랜덤포레스트 배깅 정확도')\n",
    "print(round(accuracy_score(y_test, bagging_pred), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 정확도\n",
      "0.3778\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(kernel= 'rbf', C=10.0, gamma=0.01, random_state=0)\n",
    "\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_pred = svm_clf.predict(X_test)\n",
    "\n",
    "print('SVM 정확도')\n",
    "print(round(accuracy_score(y_test, svm_pred), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 배깅 정확도\n",
      "0.5041299559471366\n"
     ]
    }
   ],
   "source": [
    "# SVM 배깅\n",
    "\n",
    "svm_clf = SVC(kernel= 'rbf', C=10.0, gamma=0.01, random_state=0)\n",
    "\n",
    "bagging_clf = BaggingClassifier(svm_clf, n_estimators=10, max_samples=0.5, max_features=0.5)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "bagging_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "print('SVM 배깅 정확도')\n",
    "print(accuracy_score(y_test, bagging_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 정확도\n",
      "0.8774779735682819\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(base_score=0.5,\n",
    "                                                      booster='gbtree',\n",
    "                                                      colsample_bylevel=1,\n",
    "                                                      colsample_bynode=1,\n",
    "                                                      colsample_bytree=1,\n",
    "                                                      eval_metric='mlogloss',\n",
    "                                                      gamma=0.3, gpu_id=-1,\n",
    "                                                      importance_type='gain',\n",
    "                                                      interaction_constraints='',\n",
    "                                                      learning_rate=0.05,\n",
    "                                                      max_delta_step=0,\n",
    "                                                      max_depth=9,\n",
    "                                                      min_child_weight=1,\n",
    "                                                      missing=np.nan,\n",
    "                                                      monotone_constraints='()',\n",
    "                                                      n_estimators=500,\n",
    "                                                      n_jobs=8,\n",
    "                                                      num_parallel_tree=1,\n",
    "                                                      objective='multi:softprob',\n",
    "                                                      random_state=0,\n",
    "                                                      reg_alpha=0, reg_lambda=1,\n",
    "                                                      scale_pos_weight=None,\n",
    "                                                      subsample=1,\n",
    "                                                      tree_method='exact',\n",
    "                                                      validate_parameters=1,\n",
    "                                                      verbosity=None)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "print('XGBoost 정확도')\n",
    "print(accuracy_score(y_test, pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 배깅 정확도\n",
      "0.8777533039647577\n"
     ]
    }
   ],
   "source": [
    "# XGB 배깅\n",
    "\n",
    "xgb_clf = XGBClassifier(base_score=0.5,\n",
    "                                                      booster='gbtree',\n",
    "                                                      colsample_bylevel=1,\n",
    "                                                      colsample_bynode=1,\n",
    "                                                      colsample_bytree=1,\n",
    "                                                      eval_metric='mlogloss',\n",
    "                                                      gamma=0.3, gpu_id=-1,\n",
    "                                                      importance_type='gain',\n",
    "                                                      interaction_constraints='',\n",
    "                                                      learning_rate=0.05,\n",
    "                                                      max_delta_step=0,\n",
    "                                                      max_depth=9,\n",
    "                                                      min_child_weight=1,\n",
    "                                                      missing=np.nan,\n",
    "                                                      monotone_constraints='()',\n",
    "                                                      n_estimators=500,\n",
    "                                                      n_jobs=8,\n",
    "                                                      num_parallel_tree=1,\n",
    "                                                      objective='multi:softprob',\n",
    "                                                      random_state=0,\n",
    "                                                      reg_alpha=0, reg_lambda=1,\n",
    "                                                      scale_pos_weight=None,\n",
    "                                                      subsample=1,\n",
    "                                                      tree_method='exact',\n",
    "                                                      validate_parameters=1,\n",
    "                                                      verbosity=None)\n",
    "\n",
    "\n",
    "bagging_clf = BaggingClassifier(xgb_clf, n_estimators=10, max_samples=0.5, max_features=0.5)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "bagging_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "print('XGBoost 배깅 정확도')\n",
    "print(accuracy_score(y_test, bagging_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM 정확도\n",
      "0.8788546255506607\n"
     ]
    }
   ],
   "source": [
    "gbm_clf = GradientBoostingClassifier()\n",
    "\n",
    "gbm_clf.fit(X_train, y_train)\n",
    "pred_gbm = gbm_clf.predict(X_test)\n",
    "\n",
    "print('GBM 정확도')\n",
    "print(accuracy_score(y_test, pred_gbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM 배깅 정확도\n",
      "0.8769273127753304\n"
     ]
    }
   ],
   "source": [
    "# GBM 배깅\n",
    "\n",
    "gbm_clf = GradientBoostingClassifier()\n",
    "\n",
    "bagging_clf = BaggingClassifier(gbm_clf, n_estimators=10, max_samples=0.5, max_features=0.5)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "bagging_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "print('GBM 배깅 정확도')\n",
    "print(accuracy_score(y_test, bagging_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM 정확도\n",
      "0.8763766519823789\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(max_depth=4, min_child_weight=1,\n",
    "                           learning_rate=0.1, num_leaves=30, num_iterations=100, n_estimators=100)\n",
    "\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "pred_lgbm = lgbm_clf.predict(X_test)\n",
    "\n",
    "print('LGBM 정확도')\n",
    "print(accuracy_score(y_test, pred_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM 배깅 정확도\n",
      "0.8780286343612335\n"
     ]
    }
   ],
   "source": [
    "# LGBM 배깅\n",
    "\n",
    "lgbm_clf = LGBMClassifier(max_depth=4, min_child_weight=1,\n",
    "                           learning_rate=0.1, num_leaves=30, num_iterations=100, n_estimators=100)\n",
    "\n",
    "\n",
    "bagging_clf = BaggingClassifier(lgbm_clf, n_estimators=10, max_samples=0.5, max_features=0.5)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "bagging_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "print('LGBM 배깅 정확도')\n",
    "print(accuracy_score(y_test, bagging_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스태킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=0)\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
    "    print(model.__class__.__name__, ' model 시작')\n",
    "    \n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        print('\\t 폴드 세트: ', folder_counter, ' 시작')\n",
    "        X_tr = X_train_n.iloc[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        X_te = X_train_n.iloc[valid_index]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1, 1)\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "        \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n",
    "    \n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 47:81]\n",
    "y = pd.factorize(data['Position simplified'])[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel='rbf', C=10.0, gamma=0.01, random_state=0)\n",
    "xgb_clf = XGBClassifier(base_score=0.5,\n",
    "                                                      booster='gbtree',\n",
    "                                                      colsample_bylevel=1,\n",
    "                                                      colsample_bynode=1,\n",
    "                                                      colsample_bytree=1,\n",
    "                                                      eval_metric='mlogloss',\n",
    "                                                      gamma=0.3, gpu_id=-1,\n",
    "                                                      importance_type='gain',\n",
    "                                                      interaction_constraints='',\n",
    "                                                      learning_rate=0.05,\n",
    "                                                      max_delta_step=0,\n",
    "                                                      max_depth=9,\n",
    "                                                      min_child_weight=1,\n",
    "                                                      missing=np.nan,\n",
    "                                                      monotone_constraints='()',\n",
    "                                                      n_estimators=500,\n",
    "                                                      n_jobs=8,\n",
    "                                                      num_parallel_tree=1,\n",
    "                                                      objective='multi:softprob',\n",
    "                                                      random_state=0,\n",
    "                                                      reg_alpha=0, reg_lambda=1,\n",
    "                                                      scale_pos_weight=None,\n",
    "                                                      subsample=1,\n",
    "                                                      tree_method='exact',\n",
    "                                                      validate_parameters=1,\n",
    "                                                      verbosity=None)\n",
    "gbm_clf = GradientBoostingClassifier()\n",
    "lgbm_clf = lgbm_clf = LGBMClassifier(max_depth=4, min_child_weight=1,\n",
    "                           learning_rate=0.1, num_leaves=30, num_iterations=100, n_estimators=100)\n",
    "rf_clf = rf_clf = RandomForestClassifier(max_depth=16, min_samples_leaf=3, min_samples_split=5,\n",
    "                               n_estimators=500)\n",
    "\n",
    "\n",
    "lr_final = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier  model 시작\n",
      "\t 폴드 세트:  0  시작\n",
      "\t 폴드 세트:  1  시작\n",
      "\t 폴드 세트:  2  시작\n",
      "\t 폴드 세트:  3  시작\n",
      "\t 폴드 세트:  4  시작\n",
      "SVC  model 시작\n",
      "\t 폴드 세트:  0  시작\n",
      "\t 폴드 세트:  1  시작\n",
      "\t 폴드 세트:  2  시작\n",
      "\t 폴드 세트:  3  시작\n",
      "\t 폴드 세트:  4  시작\n",
      "GradientBoostingClassifier  model 시작\n",
      "\t 폴드 세트:  0  시작\n",
      "\t 폴드 세트:  1  시작\n",
      "\t 폴드 세트:  2  시작\n",
      "\t 폴드 세트:  3  시작\n",
      "\t 폴드 세트:  4  시작\n",
      "XGBClassifier  model 시작\n",
      "\t 폴드 세트:  0  시작\n",
      "\t 폴드 세트:  1  시작\n",
      "\t 폴드 세트:  2  시작\n",
      "\t 폴드 세트:  3  시작\n",
      "\t 폴드 세트:  4  시작\n",
      "LGBMClassifier  model 시작\n",
      "\t 폴드 세트:  0  시작\n",
      "\t 폴드 세트:  1  시작\n",
      "\t 폴드 세트:  2  시작\n",
      "\t 폴드 세트:  3  시작\n",
      "\t 폴드 세트:  4  시작\n"
     ]
    }
   ],
   "source": [
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 5)\n",
    "svm_train, svm_test = get_stacking_base_datasets(svm_clf, X_train, y_train, X_test, 5)\n",
    "gbm_train, gbm_test = get_stacking_base_datasets(gbm_clf, X_train, y_train, X_test, 5)\n",
    "xgb_train, xgb_test = get_stacking_base_datasets(xgb_clf, X_train, y_train, X_test, 5)\n",
    "lgbm_train, lgbm_test = get_stacking_base_datasets(lgbm_clf, X_train, y_train, X_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14527, 5)\n"
     ]
    }
   ],
   "source": [
    "stack_final_X_train = np.concatenate((rf_train, svm_train, gbm_train, xgb_train, lgbm_train), axis=1)\n",
    "stack_final_X_test = np.concatenate((rf_test, svm_test, gbm_test, xgb_test, lgbm_test), axis=1)\n",
    "\n",
    "print(stack_final_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final.fit(stack_final_X_train, y_train)\n",
    "pred_final = lr_final.predict(stack_final_X_test)\n",
    "\n",
    "print((accuracy_score(y_test, pred_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC()\n",
    "rf_clf = RandomForestClassifier()\n",
    "gbm_clf = GradientBoostingClassifier()\n",
    "\n",
    "lr_final = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_train, svm_test = get_stacking_base_datasets(svm_clf, X_train, y_train, X_test, 5)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 5)\n",
    "gbm_train, gbm_test = get_stacking_base_datasets(gbm_clf, X_train, y_train, X_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_final_X_train = np.concatenate((rf_train, rf_train, gbm_train), axis=1)\n",
    "stack_final_X_test = np.concatenate((svm_test, rf_test, gbm_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(stack_final_X_train, y_train)\n",
    "pred_final = lr_final.predict(stack_final_X_test)\n",
    "\n",
    "print(accuracy_score(y_test, pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "gbm_pred = gbm_clf.predict(X_test)\n",
    "\n",
    "print(round(accuracy_score(y_test, gbm_pred, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
